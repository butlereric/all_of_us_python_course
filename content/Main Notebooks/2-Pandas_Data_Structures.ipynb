{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63091ef-c217-45fd-976d-733e4d5f2bb9",
   "metadata": {},
   "source": [
    "# Pandas Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3102320-9daf-4f97-bdde-70eb01da10d0",
   "metadata": {},
   "source": [
    "This is the first section to deal specifically with Pandas. Pandas is a powerful data analysis library that makes data science work much easier than it once was. In this notebook we will read data in without explaining how this is done. In the All of Us workspaces creating a notebook pre-fills the notebook with an import statement that pulls in your data, and so we don't need to spend a lot of time talking about how to read in data. However, it is worth knowing what data might look like inside Pandas, how to access rows, columns, and cells, and understand data types before we discuss importing data. This will make it easier to import data cleanly, as you will already have some understanding of what it means to have data formatted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd71cc",
   "metadata": {},
   "source": [
    "Pandas is separate package from the Python core, so we always need to import it. Importing a package makes the package's contents available to us in the workspace. We could use `import pandas` but by adding the `as pd` we also rename pandas to `pd` within our environment. We'll be typing the name we use a lot, and `pd` is easier to type than `pandas` so, by convention, this is what everyone does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1dec84",
   "metadata": {},
   "source": [
    "The next block of code will randomly create some data on heart function (like you might get from a Fitbit or other wearable health monitor) and make a pandas data structure out of it. It will also print out the first five rows of data.\n",
    "\n",
    "Much like when you are using the All of Us data this code can be treated as a black box. It makes some data for us, and names it `df`. Both here and in the All of Us data all we really need to track is the name given to the dataframe and we can take it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba66e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "workout_dict = {'ID': [], 'Measurement Device': [], 'Heart Rate Max': [], 'Heart Rate Min': [], 'Heart Rate Avg': [],\n",
    "              'Duration of exercise (min)': [], 'Exercise Type': []}\n",
    "used_ids = []\n",
    "\n",
    "for x in range(0, 500):\n",
    "    id = random.randint(100000000, 999999999)\n",
    "    while id in used_ids:\n",
    "        id = random.randint(100000000, 999999999)\n",
    "    used_ids.append(id)\n",
    "    device = random.choice(['Skykandal', 'B-Wolf'])\n",
    "    mu = random.randint(65, 85)\n",
    "    min_rate = int(random.gauss(mu, 10))\n",
    "    max_rate = int(random.gauss(mu + 55, 25))\n",
    "    while max_rate <= min_rate:\n",
    "        max_rate = int(random.gauss(mu + 55, 25))\n",
    "    avg = random.gauss((max_rate + min_rate) / 2, (max_rate - min_rate) / 5)\n",
    "    duration = random.randint(10, 90)\n",
    "    exercise = random.choice(['Running', 'Running', 'Running', 'Bicycling', 'Swimming', 'Swimming',\n",
    "                              'Weight training'])\n",
    "    row = [device, min_rate, max_rate, avg, duration, exercise]\n",
    "    workout_dict['ID'].append(id)\n",
    "    workout_dict['Measurement Device'].append(row[0])\n",
    "    workout_dict['Heart Rate Min'].append(row[1])\n",
    "    workout_dict['Heart Rate Max'].append(row[2])\n",
    "    workout_dict['Heart Rate Avg'].append(row[3])\n",
    "    workout_dict['Duration of exercise (min)'].append(row[4])\n",
    "    workout_dict['Exercise Type'].append(row[5])\n",
    "\n",
    "df = pd.DataFrame(workout_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956f87f",
   "metadata": {},
   "source": [
    "The data columns are a nine-digit ID, a measurement device (so as not to step on anyone's trademarks I made up some names), a maximum, minimum, and average heart rate while exercising, the number of minutes spent exercising, and the type of exercise being done (something you wouldn't get in a real data set).\n",
    "\n",
    "The data structure we have started with is a dataframe. As you can see in the code above, we created this dataframe from a dictionary. Dataframes have some very dictionary-like attributes (like the ability to look up columns by name as if the name were the key in a key-value pair), but they add some functionality. The dataframe also knows that the second item in ID is related to the second item in Device (and every other column), which makes it much more like a spreadsheet with rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de1eff",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbbaec",
   "metadata": {},
   "source": [
    "We will start by discussing how to access a column. The code below will print the Exercise type column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338204d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Exercise Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479eedf4",
   "metadata": {},
   "source": [
    "As I mentioned above, we can simply look up the column in the dataframe (which we have named `df`, a common convention) by using the column name as the key.\n",
    "\n",
    "We can see here that the column isn't exactly a list. What it actually is is a pandas Series. It contains a lot of data in an order, but it also has an index and ends with a name, a length, and a dtype.\n",
    "\n",
    "The numbers on the left side, counting up, are the index. The index is a special column that the dataframe uses to keep track of where data is in sequence. Another way to think about it is that if we printed a row we would be printing every column at a specific index value.\n",
    "\n",
    "The name is simply the column name.\n",
    "\n",
    "The length tells us the number of entries (500 in this case).\n",
    "\n",
    "dtype tells us what kind of data are held in this column. For Exercise Type this is text, and so this column is dtype `object`. To look at other dtypes let's look at a column that is all numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Heart Rate Max']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175552bd",
   "metadata": {},
   "source": [
    "You can see that this column is dtype `int64`. That's a dtype for integer numbers , which these all are. The Heart Rate Avg column, which is numeric but not integers, will be a floating point number, probably `float64`. The numbers at the end don't matter as much, just remember that there are `int`s for integers, `float`s for non-integer numbers (ones with decimal points, really), and `object`s for text (and some other less common things).\n",
    "\n",
    "If a column is an iterable, and it sure looks like it, can we loop over it? The answer is yes, although this is often the least efficient way to do something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df['Heart Rate Max']:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86976322",
   "metadata": {},
   "source": [
    "We can also access more than one column at once. We do this by passing a list of columns we want into the square brackets. Note that this means that we have two sets of square brackets, the inner one that defines the list and an outer one that says \"get me these items from the dataframe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID', 'Measurement Device']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72892585",
   "metadata": {},
   "source": [
    "There is no need for the columns you choose to be next to each other in the dataframe. \n",
    "\n",
    "#### Write some code that gives you the columns Measurement Device, Heart Rate Min, and Duration in the space below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765839a",
   "metadata": {},
   "source": [
    "How do you find the column names? In small dataframes you can get the column names in the same way you check the data: `df.head()`. The `head` method prints out the first five rows of the dataframe by default, but you can pass it a number to make it show more.\n",
    "\n",
    "`head` is a method of the dataframe. This means that you write `name of dataframe.head()`, and `head` then shows you the head of the dataframe you named. If your dataframe was named blood_counts_frame you would write `blood_counts_frame.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dac622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9292066",
   "metadata": {},
   "source": [
    "In large datasets this won't work so well to find the column names. Once we get enough columns the `head` command will print out the first few columns, then ..., and then the last few. However, the column names are stored in the `columns` attribute of the dataframe.\n",
    "\n",
    "Attributes are accessed like methods, but they aren't functions, just variables. In this case we want the column names for the dataframe `df`. The code is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69175e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a92759",
   "metadata": {},
   "source": [
    "As you can see, this comes along with some other information. If you just want the column names you can either access the `values` attribute of columns or use the `list` function to turn `df.columns` into a list. Both methods are shown below.\n",
    "\n",
    "Note that attributes can have their own attributes! The dot notation for `df.columns.values` basically means \"values, for columns, which is part of df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29efd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312281ce",
   "metadata": {},
   "source": [
    "We can also change a column name. For instance, I don't want to be typing 'Heart Rate Max' every time I need that column, so I want to rename that column to 'Max'. To do this we use the dataframe `rename` method. `rename` can be done several different ways, but the one that is easiest to read is probably the form below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Heart Rate Max': 'Max'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf297222",
   "metadata": {},
   "source": [
    "As you can see, `rename` is a method that is \"attached\" to the dataframe, so we use dot notation for it and then it automatically knows what dataframe it is renaming. There are several ways to specify that we are renaming columns. I think the easiest one to read is the `columns` argument. `columns` then equals a dictionary where the key is the current column name and the value is the new name. Note that we then have a comma, because the whole `columns={'Heart Rate Max': 'Max'}` section was just the first argument.\n",
    "\n",
    "The `inplace` option is very common in pandas. When it is set to `True` whatever you are doing changes this dataframe. If it is set to `False` your operation generates a new dataframe that has been changed. By default it is `False`.\n",
    "\n",
    "Use of the `False` option is demonstrated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = df.rename(columns={'Max': 'MAX!!!!'}, inplace=False)\n",
    "print('Original dataframe column names:', df.columns.values)\n",
    "print('New dataframe column names:', new_frame.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1920a",
   "metadata": {},
   "source": [
    "As you can see, Max was changed to MAX!!!! only in the new frame (imaginatively named \"new_frame\") and not in the original frame. This is very useful when you aren't sure if what you are doing will work the way you think it will, and don't want to mess up your original dataframe.\n",
    "\n",
    "Since the `columns` argument of `rename` takes a dictionary you can change as many column names at once as you want.\n",
    "\n",
    "#### Below, write code that changes the names of `Heart Rate Min` to `Min` and `Duration of exercise` to `Duration`. Then print one of them, using the new name, to make sure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e1521",
   "metadata": {},
   "source": [
    "### Rows and Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c5adcf",
   "metadata": {},
   "source": [
    "Accessing rows works off of the index column of the dataframe. We can print the index below just to remind ourselves what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf1303",
   "metadata": {},
   "source": [
    "We can see that our index is just row numbers. In some cases it may be something different. You can reset the index to be the ID number, or anything else. But let's not do that, because that isn't useful for the sorts of things we're trying to do.\n",
    "\n",
    "Instead, we will use the `loc` method of the dataframe to locate the row we want, by its index. Note that `loc` uses square brackets, like indexing from a list. Below, we will print out the second row (the first row would be index 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ab350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16991f3a",
   "metadata": {},
   "source": [
    "We can also pass slice notation to `loc`. The code below replicates `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b11b1",
   "metadata": {},
   "source": [
    "We can also use `loc` on a column, to give us a single cell. The code below gives us the ID at index 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'].loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138af931",
   "metadata": {},
   "source": [
    "We can also do this with the multiple column lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID', 'Measurement Device']].loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef14eb",
   "metadata": {},
   "source": [
    "We can also get a cell directly with `loc` by specifying both row and column. If you give `loc` a tuple it will assume that it is (row, column). The code below will return the maximum heart rate ('Max') for the fourth row (index 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245471ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(3, 'Max')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bca2fa",
   "metadata": {},
   "source": [
    "#### Below, write some code that does the inverse of `head` and prints the last five rows of the dataframe. However, leave out the ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a83358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c9061",
   "metadata": {},
   "source": [
    "(If you actually just want the inverse of `head` there's a command `tail` that does this. However, the purpose of the exercise above is practice.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6ef51",
   "metadata": {},
   "source": [
    "### Modifying Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7288a",
   "metadata": {},
   "source": [
    "Adding a column to a dataframe is quite easy. Below, we will create a column that is simply the maximum heart rate divided by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78215145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Max minus 2'] = df['Max'] - 2\n",
    "df[['Max', 'Max minus 2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd57ea",
   "metadata": {},
   "source": [
    "All we had to do here was name a new column (much like adding a key to a dictionary) and set it equal to something else.\n",
    "\n",
    "However, the thing we set it equal to must be either a single item or a list equal in length to the other columns. The code below shows what happens with a single item: it is just repeated in every cell of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f648a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Two'] = 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd0293",
   "metadata": {},
   "source": [
    "This will break. We're specifying a length for the column, but it's two, and the other columns are length 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Breaking'] = [2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c382f8",
   "metadata": {},
   "source": [
    "In later notebooks we'll generate data the same length as existing columns and fill new columns with it. For now, just remember not to fill a column with data that has a length but is the wrong length.\n",
    "\n",
    "How do we remove a column? We use the `drop` method, which has a similar argument structure to `rename`. Here we just list the column names to drop. Again, `inplace=True` means \"do this to the current dataframe\".\n",
    "\n",
    "The code below drops the column Two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Two'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987de1ec",
   "metadata": {},
   "source": [
    "If you run that code above again it will fail, since the column Two no longer exists to be dropped.\n",
    "\n",
    "The `drop` command can also be used to drop rows. By default, `drop` actually expects you to drop rows, and so you can simply provide an index to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b5920",
   "metadata": {},
   "source": [
    "However, while column creation and deletion are common in analysis, adding and deleting rows is less useful. Most row deletion happens as part of filtering, which we will cover in an upcoming notebook.\n",
    "\n",
    "Creating rows is less useful (normally), and is somewhat harder to do. To add a row you create an entire new dataframe and then use the `concat` function to add the dataframes together. We won't cover this further here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55be2b1",
   "metadata": {},
   "source": [
    "### Creating Dataframes\n",
    "Creating dataframes can be useful in analysis. You may want to process data and make a new frame from the processed data only. So, how do we make a dataframe? The easiest way is to make a dictionary and then use `pd.DataFrame` to make it into a dataframe.\n",
    "\n",
    "Why `pd.DataFrame`? `DataFrame` is a function from the pandas library. The `pd.DataFrame` notation means \"DataFrame, from the pandas library\" (much like `df.head()` means \"head, of the frame df\"). This is one reason we want to import pandas and change the name to pd, because we'll type pd a lot doing analysis with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df066965",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'Column One': [1, 2], 'Column Two': [20, 78], 'Colum Three': ['C', 'K']}\n",
    "new_df = pd.DataFrame(test_dict)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca688818",
   "metadata": {},
   "source": [
    "#### Below, make a dictionary with at least three keys. One of the lists of values should be all numbers. Then turn it into a dataframe and use `head` to check that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d660d9",
   "metadata": {},
   "source": [
    "#### Now, create a new column that is your column of numbers divided by two. Again, use `head` to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db336d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861dcc6",
   "metadata": {},
   "source": [
    "#### Finally, drop one of your columns. As before, use `head` to check that it happened correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d40244",
   "metadata": {},
   "source": [
    "### Combining Dataframes\n",
    "One thing that you do often need to do when you make dataframes is merge them together. We will need some very small dataframes to see this behavior in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1 = {'ID': [1, 3, 5, 7, 9], 'B': [True, True, False, True, False]}\n",
    "dict_2 = {'ID': [1, 2, 3, 4, 5], 'C': [57, 89, 23, 12, 65]}\n",
    "dict_3 = {'ID_num': [1, 2, 3, 4, 5], 'C': [57, 89, 23, 12, 65]}\n",
    "dict_4 = {'ID': [1, 2, 3, 4, 5], 'B': [57, 89, 23, 12, 65]}\n",
    "\n",
    "frame_1 = pd.DataFrame(dict_1)\n",
    "frame_2 = pd.DataFrame(dict_2)\n",
    "frame_3 = pd.DataFrame(dict_3)\n",
    "frame_4 = pd.DataFrame(dict_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318db11",
   "metadata": {},
   "source": [
    "frame_1 and frame_2 are meant to be matched. Each contains some of the same IDs but different variables in each frame. frame_3 is frame_2 but now ID is ID_num. frame_4 is frame_2 but now C is called B.\n",
    "\n",
    "The simplest way to combine two dataframes is to just stick them together. `concat` will do this. It's not a dataframe method, so we write it `pd.concat` so Python knows to go looking for the function in pands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6742638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([frame_1, frame_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea1a8d",
   "metadata": {},
   "source": [
    "The syntax is simple: pass a list of frames to concatenate (add together).\n",
    "\n",
    "#### Below, write code to concatenate all three frames together at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c879f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d2d65",
   "metadata": {},
   "source": [
    "There are some other `concat` options, but the issue with `concat` is that items that are the same (like ID 1) just get repeated. We would really like to attach dataframes in such a way that all items with IDs get their data filled in from B and C. To do this we use `pd.merge`. Here, we can only merge two frames at a time, so instead of a list we just pass both frames as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(frame_1, frame_2)\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a62ad",
   "metadata": {},
   "source": [
    "This gave us columns ID, B, and C for all items present in ID in both dataframes (all odd numbers between 1-5). Why ID? Because the column names matched.\n",
    "       \n",
    "If we attempt to merge frame_1 with frame_4 we do need to specify what column to use. Remember, frame_4 is frame_2, except that column C is called B, which means that frame_1 and frame_4 have two identical column names. If we do nothing this is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(frame_1, frame_4)\n",
    "m.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb257a6a",
   "metadata": {},
   "source": [
    "Since no rows match in both ID and B we get nothing. We should specify that ID is the real match using the `on` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(frame_1, frame_4, on='ID')\n",
    "m.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd158b95",
   "metadata": {},
   "source": [
    "Note that this relabels the two different column Bs with underscore and a letter (x and y, by default). Columns with different names would not need this relabeling.\n",
    "\n",
    "What if the columns are the same but don't have the same name? We can name equivalent columns with `right_on` and `left_on`. Right and left refer to the position of the dataframes in the argument list. (E.g., left is the first one, right is the second one.)\n",
    "\n",
    "frame_3 was created to show this. It is frame_2, but with ID_num instead of ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(frame_1, frame_3, left_on='ID', right_on='ID_num')\n",
    "m.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e065c5",
   "metadata": {},
   "source": [
    "We still get both named columns, but we specified that ID on the left (frame_1) was to be matched to ID_num on the right (frame_3) and so we successfully combined the dataframes intelligently.\n",
    "\n",
    "However, right now we got only items in ID that were present in both dataframes.We can change this behavior with the keyword `how`. We have four simple options:\n",
    "- Inner: This is the default, where only items present in the matching column in both frames are included.\n",
    "- Outer: All items are included.\n",
    "- Left: All columns in the left dataframe (in the order you write them in `pd.merge()`) are kept, ones only present in the right dataframe are discarded.\n",
    "- Right: The opposite of left.\n",
    "\n",
    "We simply write `how=` and then the lowercase name of the join type in either single or double quotes. Here's an outer join version of merging frame_1 and frame_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(frame_1, frame_2, how='outer')\n",
    "m.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85954825",
   "metadata": {},
   "source": [
    "You'll see that any column with no data, like column B for where A is 4, becomes NaN. We'll discuss this more in the next notebook, but NaN is a blank cell.\n",
    "\n",
    "#### Below, run a left merge on frame_1 and frame_3. Remember to specify how to merge them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39f0f2",
   "metadata": {},
   "source": [
    "That concludes data structures. Next up, we'll discuss cleaning up issues like these blank cells we created in our merges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
