{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfc7798-7a76-4e2f-832a-e392922f72a7",
   "metadata": {},
   "source": [
    "# Advanced Filtering and Making Complex New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf59d1-7cb6-455f-a523-f4465feb78e7",
   "metadata": {},
   "source": [
    "In this section we'll tackle making new columns that require complex calculations or filters (or both) so we can then filter against that output, or, alternatively, just use that output.\n",
    "\n",
    "Obviously, we need our dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "workout_dict = {'ID': [], 'Measurement Device': [], 'Heart Rate Max': [], 'Heart Rate Min': [], 'Heart Rate Avg': [],\n",
    "              'Duration of exercise (min)': [], 'Exercise Type': []}\n",
    "used_ids = []\n",
    "\n",
    "for x in range(0, 500):\n",
    "    id = random.randint(100000000, 999999999)\n",
    "    while id in used_ids:\n",
    "        id = random.randint(100000000, 999999999)\n",
    "    used_ids.append(id)\n",
    "    device = random.choice(['Skykandal', 'B-Wolf'])\n",
    "    mu = random.randint(65, 85)\n",
    "    min_rate = int(random.gauss(mu, 10))\n",
    "    max_rate = int(random.gauss(mu + 55, 25))\n",
    "    while max_rate <= min_rate:\n",
    "        max_rate = int(random.gauss(mu + 55, 25))\n",
    "    avg = random.gauss((max_rate + min_rate) / 2, (max_rate - min_rate) / 5)\n",
    "    duration = random.randint(10, 90)\n",
    "    exercise = random.choice(['Running', 'Running', 'Running', 'Bicycling', 'Swimming', 'Swimming',\n",
    "                              'Weight training'])\n",
    "    row = [device, min_rate, max_rate, avg, duration, exercise]\n",
    "    workout_dict['ID'].append(id)\n",
    "    workout_dict['Measurement Device'].append(row[0])\n",
    "    workout_dict['Heart Rate Min'].append(row[1])\n",
    "    workout_dict['Heart Rate Max'].append(row[2])\n",
    "    workout_dict['Heart Rate Avg'].append(row[3])\n",
    "    workout_dict['Duration of exercise (min)'].append(row[4])\n",
    "    workout_dict['Exercise Type'].append(row[5])\n",
    "\n",
    "df = pd.DataFrame(workout_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff2d01",
   "metadata": {},
   "source": [
    "### Making New Data Labels\n",
    "If we were interested in people with faster heart rates it would be easy enough to write a filter, say, `df[df['Heart Rate Avg'] >= 100]` that would return only those people. However, we might not be only interested in those people, but interested in the difference between people who have those faster heart rates and those who don't. In that case we might want to make a new column where people with an average heart rate over 100 were labeled \"True\" and those with a slower heart rate were labeled \"False\". (While we aren't there yet, this sort of thing would make it easy to get summary statistics for these groups separately.)\n",
    "\n",
    "A quick reminder: making a new column is as simple as setting that column equal to something. `df['Something'] = 3` would make a column called \"Something\" where every value was 3.\n",
    "\n",
    "We can use this basic syntax to make a new column with True/False values by passing an expression very much like a filter. Because we're going to want to try several variations on this, the code block below begins by making a copy of df that we'll modify, so we can start fresh by going back to df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a408894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['Fast Heart Rate'] = df2['Heart Rate Avg'] > 100\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24295c05",
   "metadata": {},
   "source": [
    "This works up to a point. What if we wanted a column that showed us a range? That also works, using a more complex expression. \n",
    "\n",
    "#### Write an expression below that makes a column that is True only if someone's average heart rate is between 95-105. (Note: you'll need to enclose the whole thing in parentheses so that Python knows to turn it into a single True or False.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f7f8f",
   "metadata": {},
   "source": [
    "The point where this begins to collapse is where we need more than two labels, or really anything complex. At this point we really want to pass the row to a function that can evaluate the value at a given column and return a value. However, if we attempt to loop over a dataframe we don't get the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d38604",
   "metadata": {},
   "source": [
    "Instead, pandas supplies us with an `iterrows` method that lets us iterate over the rows. It's a method, so you call it as a function, and it produces an iterable. However, the row returned is not a simple list, and it's a copy not a view, and so changing it doesn't change the dataframe. Instead, you need to look up the original dataframe row by index and change that. It's a mess, and so there's a specific pandas method that handles this all much more cleanly.\n",
    "\n",
    "However, if you want to see what you're missing, the code to do this the hard way is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44351793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe, just because we don't want to mess up our real dataframe for this example\n",
    "df3 = df.copy()\n",
    "\n",
    "# make a new column and give it a default value\n",
    "df3['Heart Rate Class'] = 'Middle'\n",
    "\n",
    "# generate the iterrows object and iterate over it\n",
    "# iterrows returns an iterable with two items in it, so we unpack that all at once\n",
    "for index, row in df.iterrows():\n",
    "    # check the age, if it shouldn't be the default do something\n",
    "    if row['Heart Rate Avg'] >= 110:\n",
    "        # use loc with a tuple to access the original cell and change it\n",
    "        df3.loc[(index, 'Heart Rate Class')] = 'Fast'\n",
    "    elif row['Heart Rate Avg'] < 90:\n",
    "        df3.loc[(index, 'Heart Rate Class')] = 'Slow'\n",
    "        \n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a3871",
   "metadata": {},
   "source": [
    "Hopefully at this point you're ready to see the simple way.\n",
    "\n",
    "The simple way uses a user-defined function and `apply`. `apply` is a dataframe method that has two main arguments to pay attention to: a function that `apply` sends everything to, and an axis that determines whether it sends rows or columns (0 is columns, 1 is rows).\n",
    "\n",
    "The example below just demonstrates how apply works, without making a new column. We'll define a function that just prints the average heart rate in the row and then apply that function over each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointless_print(row):\n",
    "    print(row['Heart Rate Avg'])\n",
    "    \n",
    "df.apply(pointless_print, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a28630",
   "metadata": {},
   "source": [
    "If we altered the function slightly, so that it returns the value instead of printing it, we would get a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10607833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_avg(row):\n",
    "    return row['Heart Rate Avg']\n",
    "\n",
    "df.apply(return_avg, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9789170",
   "metadata": {},
   "source": [
    "Because the Series is as long as the columns in the dataframe we can easily add it as a column. Let's modify the function to reclassify heart rates according to our earlier categories, and then attach the output as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()\n",
    "\n",
    "def classify_avg(row):\n",
    "    if row['Heart Rate Avg'] < 90:\n",
    "        rate = 'Slower'\n",
    "    elif row['Heart Rate Avg'] < 110:\n",
    "        rate = 'Middle'\n",
    "    else:\n",
    "        rate = 'Faster'\n",
    "    return rate\n",
    "\n",
    "df4['Heart Rate Class'] = df4.apply(classify_avg, axis=1)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3eeb14",
   "metadata": {},
   "source": [
    "As you can see, this allows us to do fairly complex processing, since we can hand off an entire row to a function of whatever complexity we need.\n",
    "\n",
    "Before we go further, practice this yourself.\n",
    "#### In the block below calculate a new column called \"Midpoint\" that is the average of the heart rate maximum and minimums, using apply. (This can be done without using apply, but that's not the point of this exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405498c",
   "metadata": {},
   "source": [
    "We can even get multiple columns at once. If the function returns multiple values and  we pass the argument `result_type='expand'` we get a small dataframe back. We could either join this dataframe to our existing one, or, more simply, declare that this dataframe is several new columns in the existing dataframe. We do this the same way we accessed multiple columns at once, using a list of new columns. E.g., getting or setting columns A and B would be `df[['A', 'B']]`.\n",
    "\n",
    "In the example below I will run this operation on a copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.copy()\n",
    "\n",
    "# what is important about this function is that it returns two items, not one\n",
    "def multiple_returns(row):\n",
    "    aerobic_exercise = True\n",
    "    heart_rate_class = 'Middle'\n",
    "    if row['Exercise Type'] == 'Weight training':\n",
    "        aerobic_exercise = False\n",
    "    if row['Heart Rate Avg'] < 90:\n",
    "        heart_rate_class = 'Low'\n",
    "    elif row['Heart Rate Avg'] > 110:\n",
    "        heart_rate_class = 'High'\n",
    "    return aerobic_exercise, heart_rate_class\n",
    "\n",
    "\n",
    "# attach the output of apply to the dataframe\n",
    "df5[['Aerobic Exercise', 'Heart Rate Class']] = df5.apply(multiple_returns, axis=1, result_type='expand')\n",
    "df5.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478c9f4",
   "metadata": {},
   "source": [
    "`apply` can also be used on a single column. For instance, the code below will use a modified version of the classify_avg function we defined earlier on the Heart Rate Avg column, without a need to look up the average heart rate column in a row. We'll use yet another copy of df for this, and give it a classifing column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_avg(avg):\n",
    "    if avg < 90:\n",
    "        rate_class = 'Low'\n",
    "    elif avg < 110:\n",
    "        rate_class = 'Middle'\n",
    "    else:\n",
    "        rate_class = 'High'\n",
    "    return rate_class\n",
    "\n",
    "\n",
    "df6 = df.copy()\n",
    "\n",
    "df6['Class'] = df6['Heart Rate Avg'].apply(classify_avg)\n",
    "df6.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fb290",
   "metadata": {},
   "source": [
    "#### In the cell below, try passing a single column to apply that should return half the exercise time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9202a",
   "metadata": {},
   "source": [
    "`apply` also allows you to define functions on the spot. There's no need to do this, but there are times when it is useful. Below, we'll use the pre-existing `lower()` method to make the Exercise Type column labels all lowercase. Since `lower` is a method we can't just pass things to it, it is attached to text using dot notation. What we can do is make use of Python's `lambda` to make an on-the-spot function.\n",
    "\n",
    "(If `lower` is unclear, think of it this way: if `text` is a text variable then `text.lower()` gives us the lowercase version of `text`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Exercise Type'] = df7['Exercise Type'].apply(lambda x: x.lower())\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacab4be",
   "metadata": {},
   "source": [
    "The code below does exactly the same thing (to a different column), so don't feel like you have to use `lambda`. The form below takes more lines of code, but that's fine when you're starting out, and is easier to read for some people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f90b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    return text.lowercase()\n",
    "\n",
    "df7['Class lower'] = df7['Class'].apply(lambda x: x.lower())\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d9cb0",
   "metadata": {},
   "source": [
    "However, if you want to use lambda the format isn't too difficult. `lambda x:` means \"we're making a function which takes an argument, x\", so `lambda x: x.lower()` means \"we're making a function that takes an argument, x, and then returns x.lower()\".\n",
    "\n",
    "At this point, you have a lot of different ways to use `apply`. Using `apply` to make a column is often a precursor to filtering on that new column. \n",
    "\n",
    "#### So, for practice using apply, assume that we know that B-Wolf devices consistently measure 2 bpm lower than Skykandal devices. Also, Skykandal devices react poorly to water, and measure 5 bpm too high if you're swimming. Write a block of code that bumps up all B-Wolf device heart rate measures by 2, subtracts 5 from Skykandal heart rate measures for swimmers only, and then filters on the corrected rates so that we only have people with average heart rates above 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7922221",
   "metadata": {},
   "source": [
    "Now, it's time to look at summarizing the data from all of these filtering operations and new columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
